{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ライントレース+物体検知"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/usr/lib/python36.zip', '/usr/lib/python3.6', '/usr/lib/python3.6/lib-dynload', '', '/home/jetbot/.local/lib/python3.6/site-packages', '/usr/local/lib/python3.6/dist-packages', '/usr/local/lib/python3.6/dist-packages/torchvision-0.4.0a0+d31eafa-py3.6-linux-aarch64.egg', '/usr/local/lib/python3.6/dist-packages/Adafruit_SSD1306-1.6.2-py3.6.egg', '/usr/local/lib/python3.6/dist-packages/Adafruit_MotorHAT-1.4.0-py3.6.egg', '/usr/local/lib/python3.6/dist-packages/Adafruit_GPIO-1.0.4-py3.6.egg', '/usr/local/lib/python3.6/dist-packages/spidev-3.4-py3.6-linux-aarch64.egg', '/usr/local/lib/python3.6/dist-packages/Adafruit_PureIO-1.0.4-py3.6.egg', '/usr/local/lib/python3.6/dist-packages/jetbot-0.4.0-py3.6.egg', '/usr/lib/python3/dist-packages', '/usr/lib/python3.6/dist-packages', '/usr/local/lib/python3.6/dist-packages/IPython/extensions', '/home/jetbot/.ipython', '/home/jetbot/g031r066/darknet']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append( \"/home/jetbot/g031r066/darknet\" )\n",
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 物体検知側の下準備"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import darknet\n",
    "import darknet_images\n",
    "import time\n",
    "\"\"\"\n",
    "load model description and weights from config files\n",
    "args:\n",
    "    config_file (str): path to .cfg model file\n",
    "    data_file (str): path to .data model file\n",
    "    weights (str): path to weights\n",
    "returns:\n",
    "    network: trained model\n",
    "    class_names\n",
    "    class_colors\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "network, class_names, class_colors = darknet.load_network(\n",
    "    '/home/jetbot/g031r066/darknet/cfg/yolov4-tiny.cfg',  \n",
    "    '/home/jetbot/g031r066/darknet/cfg/coco.data', \n",
    "    '/home/jetbot/g031r066/darknet/weights/yolov4-tiny.weights'\n",
    "    )\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "network, class_names, class_colors = darknet.load_network(\n",
    "        '/home/jetbot/g031r066/darknet/custom/yolov4-tiny-custom.cfg', \n",
    "        '/home/jetbot/g031r066/darknet/custom/custom.data',  \n",
    "        '/home/jetbot/g031r066/darknet/custom/backup/yolov4-tiny-custom_final.weights'\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ライントレース側の下準備"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# インポート\n",
    "import torchvision\n",
    "import torch\n",
    "\n",
    "# 自分で作成したライントレースのモデルを読み込む\n",
    "model_rf = torchvision.models.resnet18(pretrained=False)\n",
    "model_rf.fc = torch.nn.Linear(512, 2)\n",
    "model_rf.load_state_dict(torch.load('/home/jetbot/g031r066/note_nvidia/road_following/best_steering_models/[nvidia_circuit-ver1.2]_res18.pth'))\n",
    "# GPU側に転送\n",
    "device = torch.device('cuda')\n",
    "model_rf = model_rf.to(device)\n",
    "model_rf = model_rf.eval().half()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# カメラから読み込む映像への前処理を実装\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "import cv2\n",
    "import PIL.Image\n",
    "import numpy as np\n",
    "\n",
    "mean = torch.Tensor([0.485, 0.456, 0.406]).cuda().half()\n",
    "std = torch.Tensor([0.229, 0.224, 0.225]).cuda().half()\n",
    "\n",
    "def preprocess(image):\n",
    "    image = PIL.Image.fromarray(image)\n",
    "    image = transforms.functional.to_tensor(image).to(device).half()\n",
    "    image.sub_(mean[:, None, None]).div_(std[:, None, None])\n",
    "    return image[None, ...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 諸々インポート\n",
    "from IPython.display import display\n",
    "import ipywidgets\n",
    "import traitlets\n",
    "\n",
    "# 駆動系周りの準備\n",
    "from jetbot import Robot\n",
    "\n",
    "robot = Robot()  # 駆動系を制御できるモジュールのインポート\n",
    "\n",
    "# 制御するバーの設定\n",
    "speed_gain_slider = ipywidgets.FloatSlider(min=0.0, max=1.0, step=0.01, description='speed gain')\n",
    "steering_gain_slider = ipywidgets.FloatSlider(min=0.0, max=1.0, step=0.01, value=0.05, description='steering gain')\n",
    "steering_dgain_slider = ipywidgets.FloatSlider(min=0.0, max=0.5, step=0.001, value=0.0, description='steering kd')\n",
    "steering_bias_slider = ipywidgets.FloatSlider(min=-0.3, max=0.3, step=0.01, value=0.0, description='steering bias')\n",
    "# 描画\n",
    "#display(speed_gain_slider, steering_gain_slider, steering_dgain_slider, steering_bias_slider)\n",
    "\n",
    "# 自Jetbotにおいては、以下の設定だと良い感じに動く\n",
    "# speed gain = 0.1 2022/09/09 0.15の方が綺麗\n",
    "# steering gain = 0.05\n",
    "# steering kd = 0\n",
    "# steering gain = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 現在の動作を示すバーを描画\n",
    "x_slider = ipywidgets.FloatSlider(min=-1.0, max=1.0, description='x')\n",
    "y_slider = ipywidgets.FloatSlider(min=0, max=1.0, orientation='vertical', description='y')\n",
    "steering_slider = ipywidgets.FloatSlider(min=-1.0, max=1.0, description='steering')\n",
    "speed_slider = ipywidgets.FloatSlider(min=0, max=1.0, orientation='vertical', description='speed')\n",
    "\n",
    "#display(ipywidgets.HBox([y_slider, speed_slider]))\n",
    "#display(x_slider, steering_slider)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 本処理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jetbot import Camera, bgr8_to_jpeg\n",
    "import datetime\n",
    "import time\n",
    "\n",
    "# カメラ起動\n",
    "camera = Camera(width=300, height=300, capture_width=1280, capture_height=720)  # デフォルトでは Camera(width=224, height=224, fps=21, capture_width=3280, capture_height=2464)\n",
    "image_widget = ipywidgets.Image()\n",
    "traitlets.dlink((camera, 'value'), (image_widget, 'value'), transform=bgr8_to_jpeg)\n",
    "\n",
    "blocked_widget = ipywidgets.FloatSlider(min=0.0, max=1.0, value=0.0, description='blocked')\n",
    "image_widget = ipywidgets.Image(format='jpeg', width=300, height=300)\n",
    "bbox_widget = ipywidgets.Image(format='jpeg', width=300, height=300)\n",
    "label_widget = ipywidgets.IntText(value=1, description='tracked label')\n",
    "speed_widget = ipywidgets.FloatSlider(value=0.4, min=0.0, max=1.0, description='speed')\n",
    "turn_gain_widget = ipywidgets.FloatSlider(value=0.8, min=0.0, max=2.0, description='turn gain')\n",
    "'''\n",
    "display(ipywidgets.VBox([\n",
    "    ipywidgets.HBox([image_widget, blocked_widget),\n",
    "    label_widget,\n",
    "    speed_widget,\n",
    "    turn_gain_widget\n",
    "]))\n",
    "'''\n",
    "width = int(image_widget.width)\n",
    "height = int(image_widget.height)\n",
    "\n",
    "def detection_center(detection):\n",
    "    \"\"\"Computes the center x, y coordinates of the object\"\"\"\n",
    "    bbox = detection['bbox']\n",
    "    center_x = (bbox[0] + bbox[2]) / 2.0 - 0.5\n",
    "    center_y = (bbox[1] + bbox[3]) / 2.0 - 0.5\n",
    "    return (center_x, center_y)\n",
    "    \n",
    "def norm(vec):\n",
    "    \"\"\"Computes the length of the 2D vector\"\"\"\n",
    "    return np.sqrt(vec[0]**2 + vec[1]**2)\n",
    "\n",
    "def closest_detection(detections):\n",
    "    \"\"\"Finds the detection closest to the image center\"\"\"\n",
    "    closest_detection = None\n",
    "    for det in detections:\n",
    "        center = detection_center(det)\n",
    "        if closest_detection is None:\n",
    "            closest_detection = det\n",
    "        elif norm(detection_center(det)) < norm(detection_center(closest_detection)):\n",
    "            closest_detection = det\n",
    "    return closest_detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import queue\n",
    "from IPython.display import clear_output\n",
    "\n",
    "q = queue.Queue()  # メインスレッド<->サブスレッド で画像をやり取りするためのキューを作っておく\n",
    "angle = 0.0\n",
    "angle_last = 0.0\n",
    "# ライントレースを実装する関数\n",
    "def road_following(snapshot):\n",
    "    global angle, angle_last\n",
    "\n",
    "    xy = model_rf(preprocess(snapshot)).detach().float().cpu().numpy().flatten()\n",
    "    x = xy[0]\n",
    "    y = (0.5 - xy[1]) / 2.0\n",
    "    \n",
    "    x_slider.value = x\n",
    "    y_slider.value = y\n",
    "    \n",
    "    speed_slider.value = speed_gain_slider.value\n",
    "    \n",
    "    angle = np.arctan2(x, y)\n",
    "    pid = angle * steering_gain_slider.value + (angle - angle_last) * steering_dgain_slider.value\n",
    "    angle_last = angle\n",
    "    \n",
    "    steering_slider.value = pid + steering_bias_slider.value\n",
    "    \n",
    "    robot.left_motor.value = max(min(speed_slider.value + steering_slider.value, 1.0), 0.0)\n",
    "    robot.right_motor.value = max(min(speed_slider.value - steering_slider.value, 1.0), 0.0)\n",
    "    \n",
    "\n",
    "# 物体検知を実装する関数\n",
    "def object_detection(snapshot):\n",
    "    \n",
    "    re = 0\n",
    "    prev_time = time.time()\n",
    "    thresh = .45\n",
    "    image, detections = darknet_images.image_detection(snapshot, network, class_names, class_colors, thresh)\n",
    "    darknet.print_detections(detections, True)  # True: 各物体の座標・幅・高さを表示\n",
    "    fps = int(1/(time.time() - prev_time))\n",
    "    print(\"FPS: {}\".format(fps), flush=True)\n",
    "    print(\"Predicted in {} seconds\".format((time.time() - prev_time)), flush=True)\n",
    "    \n",
    "    label_list=[]\n",
    "    confidence_list=[]\n",
    "    bbox_list=[]\n",
    "    for label, confidence, bbox in detections: \n",
    "        label_list.append(label)\n",
    "        confidence_list.append(confidence)\n",
    "        bbox_list.append(bbox)\n",
    "    \n",
    "    if(\"Traffic light\" in label_list):  # 信号機を検知した場合\n",
    "        # 対象の信号機を1つに絞る\n",
    "        trafficlight_label_list=[]\n",
    "        trafficlight_confidence_list=[]\n",
    "        trafficlight_bbox_list=[]\n",
    "        for label, confidence, bbox in detections: \n",
    "            if(label==\"Traffic light\"):\n",
    "                trafficlight_label_list.append(label)\n",
    "                trafficlight_confidence_list.append(confidence)\n",
    "                trafficlight_bbox_list.append(bbox)\n",
    "        \n",
    "        target_index = trafficlight_confidence_list.index(max(trafficlight_confidence_list))  # 検知した信号機のうち、1番信頼度の高いものを対象にし、そのindexを取ってくる\n",
    "        target_bbox =  trafficlight_bbox_list[target_index]  # 取ってきたindexを基に、1版信頼度の高い信号機の座標を保存\n",
    "        print(\"target_bbox: {}\".format(target_bbox), flush=True)\n",
    "        \n",
    "        xmin, ymin, xmax, ymax = darknet.bbox2points(target_bbox)\n",
    "        cropped_image = image[ymin+1:ymax-1, xmin+1:xmax-1]  # bboxの枠線が映らないようにちょっと狭めに切り取る\n",
    "        \n",
    "        # 1.HSVに変換して白黒でマスク(2値化)\n",
    "        # cropped_imageが空になっていることがある、要処理追加\n",
    "        hsv_cropped_image = cv2.cvtColor(cropped_image, cv2.COLOR_BGR2HSV)\n",
    "        # 信号機の目:白,それ以外:黒 でマスクする \n",
    "        # 彩度(s)・明度(v)で絞り込む. 信号機の目は大体鮮やかなのでそのようになるように指定\n",
    "        lower = np.array([0, 200,100])           # 抽出する色の下限(h,s,v)\n",
    "        upper = np.array([150, 255 , 255])        # 抽出する色の上限(h,s,v)\n",
    "        mask_traffic_light = cv2.inRange(hsv_cropped_image, lower, upper) # inRangeで元画像を２値化\n",
    "        # 1の結果を基に、信号機の目部分の色はそのままに、それ以外を黒でマスク\n",
    "        target = cv2.bitwise_and(hsv_cropped_image,hsv_cropped_image, mask=mask_traffic_light)\n",
    "        # 信号機の目以外は黒色(H=0)でマスクしている為、Hの平均値を出しても小さい値にしかならないので意味がない\n",
    "        # → なのでHのminとmaxを出す(min要らないけど)\n",
    "        h_min = target.T[0].flatten().min()\n",
    "        h_max = target.T[0].flatten().max()\n",
    "        \n",
    "        # Hの最大値で判別する\n",
    "        if(0 <= h_max <= 30):\n",
    "            print(\"Traffic_light : red\", flush=True)\n",
    "            # 赤信号なので一時停止\n",
    "            robot.left_motor.value = 0.0\n",
    "            robot.right_motor.value = 0.0\n",
    "            re = -1\n",
    "            time.sleep(0.1) \n",
    "        elif(30<h_max and h_max<=150):  # 緑と青は取り敢えず一緒にした\n",
    "            print(\"Traffic_light : green\", flush=True)\n",
    "            re = 0\n",
    "        else:\n",
    "            print(\"Traffic_light : none\", flush=True)\n",
    "            re = -2\n",
    "    else:  # 信号機を検知できなかった場合\n",
    "        now = datetime.datetime.now().isoformat(sep=' ', timespec='milliseconds')\n",
    "        filename = '/home/jetbot/g031r066/darknet/bad_snapshot/' + str(now) + '.jpg'\n",
    "        #cv2.imwrite(filename, snapshot)  # 信号機を検知できなかったときのスナップショットを保存\n",
    "    \n",
    "    clear_output(True)\n",
    "            \n",
    "    q.put(re)\n",
    "    q.put(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "\n",
    "def execute(change):\n",
    "    snapshot = change['new']  # 映像読み込み type(snapshot) = numpy.ndarray\n",
    "    \n",
    "    # 物体検知をサブスレッドで行う\n",
    "    thread_od = threading.Thread(target = object_detection, args=(snapshot,))\n",
    "    thread_od.start()\n",
    "    thread_od.join()\n",
    "    re = q.get()  # 物体検知の結果を示す返り値(int)を格納\n",
    "    image = q.get()  # bboxを描画した画像を格納\n",
    "    \n",
    "    if(re == -1):  # 赤信号時\n",
    "        print(\"road_following don't work.(re == -1)\")\n",
    "    else:\n",
    "        # 赤信号ではないときのみ、ライントレースを行う\n",
    "        print(\"road_following is work.\")\n",
    "        thread_rf = threading.Thread(target = road_following, args=(snapshot,))  # サブスレッドで行う\n",
    "        thread_rf.start()\n",
    "        thread_rf.join()\n",
    "    \n",
    "    # 出力されているカメラ映像の更新\n",
    "    bbox_widget.value = bgr8_to_jpeg(image)\n",
    "    #bbox_widget.value = bgr8_to_jpeg(snapshot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bce2b0875f9d4837a33f77642a3558d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Image(value=b'', format='jpeg', height='300', width='300'), VBox(children=(FloatSlider(value=0.…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from ipywidgets import HBox, VBox\n",
    "\n",
    "display(HBox([bbox_widget, VBox([speed_gain_slider, steering_gain_slider, steering_dgain_slider, steering_bias_slider])]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "road_following is work.\n",
      "\n",
      "Objects:\n",
      "Traffic light: 48.44%    (left_x: 260   top_y:  90   width:   66   height:  201)\n",
      "FPS: 11\n",
      "Predicted in 0.08989381790161133 seconds\n",
      "target_bbox: (260.1303405761719, 89.51848602294922, 65.86913299560547, 200.8131866455078)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-170:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/threading.py\", line 864, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-9-51d5e4c6d685>\", line 70, in object_detection\n",
      "    hsv_cropped_image = cv2.cvtColor(cropped_image, cv2.COLOR_BGR2HSV)\n",
      "cv2.error: OpenCV(4.1.1) /home/nvidia/host/build_opencv/nv_opencv/modules/imgproc/src/color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "execute({'new': camera.value})\n",
    "camera.observe(execute, names='value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "road_following is work.\n"
     ]
    }
   ],
   "source": [
    "camera.unobserve(execute, names='value')\n",
    "\n",
    "time.sleep(0.1)  # add a small sleep to make sure frames have finished processing\n",
    "camera.stop()\n",
    "robot.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-f94950a553ef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcamera\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mrobot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/jetbot-0.4.0-py3.6.egg/jetbot/camera.py\u001b[0m in \u001b[0;36mstop\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     83\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'thread'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrestart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1054\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1055\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1056\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wait_for_tstate_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1057\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1058\u001b[0m             \u001b[0;31m# the behavior of a negative timeout isn't documented, but\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/threading.py\u001b[0m in \u001b[0;36m_wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1070\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlock\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# already determined that the C code is done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1071\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_stopped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1072\u001b[0;31m         \u001b[0;32melif\u001b[0m \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1073\u001b[0m             \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1074\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "camera.stop()\n",
    "robot.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-aa52d85d2633>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcamera\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/jetbot-0.4.0-py3.6.egg/jetbot/camera.py\u001b[0m in \u001b[0;36mrestart\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrestart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/jetbot-0.4.0-py3.6.egg/jetbot/camera.py\u001b[0m in \u001b[0;36mstop\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     83\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'thread'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrestart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1054\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1055\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1056\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wait_for_tstate_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1057\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1058\u001b[0m             \u001b[0;31m# the behavior of a negative timeout isn't documented, but\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/threading.py\u001b[0m in \u001b[0;36m_wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1070\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlock\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# already determined that the C code is done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1071\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_stopped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1072\u001b[0;31m         \u001b[0;32melif\u001b[0m \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1073\u001b[0m             \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1074\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "camera.restart()\n",
    "time.sleep(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "robot.left_motor.value = 0.0\n",
    "robot.right_motor.value = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
