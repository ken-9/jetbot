{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'darknet'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-3105ab448c71>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mdarknet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdarknet_images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \"\"\"\n\u001b[1;32m      5\u001b[0m \u001b[0mload\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0mdescription\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mweights\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mconfig\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'darknet'"
     ]
    }
   ],
   "source": [
    "import darknet\n",
    "import darknet_images\n",
    "import time\n",
    "\"\"\"\n",
    "load model description and weights from config files\n",
    "args:\n",
    "    config_file (str): path to .cfg model file\n",
    "    data_file (str): path to .data model file\n",
    "    weights (str): path to weights\n",
    "returns:\n",
    "    network: trained model\n",
    "    class_names\n",
    "    class_colors\n",
    "\"\"\"\n",
    "network, class_names, class_colors = darknet.load_network(\n",
    "        '/home/jetbot/g031r066/darknet/custom/yolov4-tiny-custom.cfg', \n",
    "        '/home/jetbot/g031r066/darknet/custom/custom.data',  \n",
    "        '/home/jetbot/g031r066/darknet/custom/backup/yolov4-tiny-custom_final.weights'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/usr/lib/python36.zip',\n",
       " '/usr/lib/python3.6',\n",
       " '/usr/lib/python3.6/lib-dynload',\n",
       " '',\n",
       " '/home/jetbot/.local/lib/python3.6/site-packages',\n",
       " '/usr/local/lib/python3.6/dist-packages',\n",
       " '/usr/local/lib/python3.6/dist-packages/torchvision-0.4.0a0+d31eafa-py3.6-linux-aarch64.egg',\n",
       " '/usr/local/lib/python3.6/dist-packages/Adafruit_SSD1306-1.6.2-py3.6.egg',\n",
       " '/usr/local/lib/python3.6/dist-packages/Adafruit_MotorHAT-1.4.0-py3.6.egg',\n",
       " '/usr/local/lib/python3.6/dist-packages/Adafruit_GPIO-1.0.4-py3.6.egg',\n",
       " '/usr/local/lib/python3.6/dist-packages/spidev-3.4-py3.6-linux-aarch64.egg',\n",
       " '/usr/local/lib/python3.6/dist-packages/Adafruit_PureIO-1.0.4-py3.6.egg',\n",
       " '/usr/local/lib/python3.6/dist-packages/jetbot-0.4.0-py3.6.egg',\n",
       " '/usr/lib/python3/dist-packages',\n",
       " '/usr/lib/python3.6/dist-packages',\n",
       " '/usr/local/lib/python3.6/dist-packages/IPython/extensions',\n",
       " '/home/jetbot/.ipython']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Objects:\n",
      "Traffic light: 58.88%    (left_x: 259   top_y:  241   width:   88   height:  218)\n",
      "FPS: 9\n",
      "Predicted in 0.10379338264465332 seconds\n"
     ]
    }
   ],
   "source": [
    "images_path = 'custom/test_traffic_light_red.jpg'\n",
    "images = darknet_images.load_images(images_path)\n",
    "\n",
    "image_name = images[0]\n",
    "prev_time = time.time()\n",
    "thresh = .30\n",
    "image, detections = darknet_images.image_detection(image_name, network, class_names, class_colors, thresh)\n",
    "\n",
    "darknet.print_detections(detections, True)  # True: 各物体の座標・幅・高さを表示\n",
    "fps = int(1/(time.time() - prev_time))\n",
    "print(\"FPS: {}\".format(fps))\n",
    "print(\"Predicted in {} seconds\".format((time.time() - prev_time)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d95521d7ec634420930f13de6fb1f894",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image(value=b'', format='jpg', height='400', width='400')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display\n",
    "import ipywidgets\n",
    "\n",
    "image_widget = ipywidgets.Image(format='jpg', width=400, height=400)\n",
    "display(image_widget)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# drawn_imagesの型はnumpy.ndarray、ipywidgetsはbytesなので表示出来る型に変換する必要がある\n",
    "bytes_images = cv2.imencode(\".jpg\", image, (cv2.IMWRITE_JPEG_QUALITY, 100))[1].tobytes()  # [0]:変換が成功したかどうかのbool値 [1]:エンコードされたバイト列を tuple で返す。\n",
    "image_widget.value = bytes_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Traffic light']\n",
      "['58.88']\n",
      "(259.0245666503906, 240.69375610351562, 87.5177993774414, 218.49827575683594)\n"
     ]
    }
   ],
   "source": [
    "label_list=[]\n",
    "confidence_list=[]\n",
    "bbox_list=[]\n",
    "for label, confidence, bbox in detections: \n",
    "    label_list.append(label)\n",
    "    confidence_list.append(confidence)\n",
    "    bbox_list.append(bbox)\n",
    "\n",
    "print(label_list)   \n",
    "print(confidence_list)\n",
    "print(*bbox_list,sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "215 131 303 350\n"
     ]
    }
   ],
   "source": [
    "# 信号機部分を切り出し\n",
    "from decimal import Decimal, ROUND_HALF_UP\n",
    "\n",
    "i=0\n",
    "xmin, ymin, xmax, ymax = darknet.bbox2points(bbox_list[i])\n",
    "print(xmin, ymin, xmax, ymax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imwrite(\"normal_image.jpg\",image)\n",
    "trimmed_image = image[ymin+1:ymax-1, xmin+1:xmax-1]  # bboxの枠線が映らないようにちょっと狭めに切り取る\n",
    "cv2.imwrite(\"trimmed_image.jpg\", trimmed_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hue: 96.80\n",
      "Salute: 149.89\n",
      "Value: 122.44\n",
      "Traffic_light : green\n"
     ]
    }
   ],
   "source": [
    "# 色基準で2値化する。\n",
    "hsv = cv2.cvtColor(trimmed_image, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "# HSV平均値を取得\n",
    "# flattenで一次元化しmeanで平均を取得 \n",
    "h = hsv.T[0].flatten().mean()\n",
    "s = hsv.T[1].flatten().mean()\n",
    "v = hsv.T[2].flatten().mean()\n",
    "\n",
    "# HSV平均値を出力\n",
    "# uHeは[0,179], Saturationは[0,255]，Valueは[0,255]\n",
    "print(\"Hue: %.2f\" % (h))\n",
    "print(\"Salute: %.2f\" % (s))\n",
    "print(\"Value: %.2f\" % (v))\n",
    "\n",
    "# 信号機の色を判別\n",
    "# 参考1 : https://algorithm.joho.info/programming/python/opencv-color-detection/\n",
    "# 参考2 : https://tomosoft.jp/design/?p=44101\n",
    "if((h>=0 and h<=30) or ((h>=150 and h<=179))):\n",
    "    print(\"Traffic_light : red\")\n",
    "elif(h>30 and h<=150):  # 緑と青は取り敢えず一緒にした\n",
    "    print(\"Traffic_light : green\")\n",
    "else:\n",
    "    print(\"Traffic_light : none\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
